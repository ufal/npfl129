### Lecture: 10. Gradient Boosted Decision Trees
#### Date: Dec 02
#### Slides: https://ufal.mff.cuni.cz/~courses/npfl129/2425/slides/?10
#### Reading: https://ufal.mff.cuni.cz/~courses/npfl129/2425/slides.pdf/npfl129-2425-10.pdf,PDF Slides
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl129/2425/npfl129-2425-10-czech.mp4, CS Lecture
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl129/2425/npfl129-2425-10-english.mp4, EN Lecture
#### Lecture assignment: gradient_boosting
#### Lecture assignment: human_activity_recognition
#### Questions: #lecture_10_questions

**Learning objectives.** After the lecture you should be able to

- Explain second-order optimization methods

- Implement gradient boosted decision trees for regression and classification

- Decide what supervised machine learning approach is suitable for particular
  problems

**Covered topics** and where to find more:

- Gradient boosting decision trees [Paper [XGBoost: A Scalable Tree Boosting System](https://arxiv.org/abs/1603.02754)]

  - [Interactive Playground](http://arogozhnikov.github.io/2016/07/05/gradient_boosting_playground.html) by Alex Rogozhnikov

After the lecture: short and non-comprehensive [**recap quiz**](http://quest.ms.mff.cuni.cz/class-quiz/quiz/ml_intro_lect10).
