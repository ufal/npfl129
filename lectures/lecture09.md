### Lecture: 9. Decision Trees, Random Forests
#### Date: Nov 24, Nov 27
#### Slides: https://ufal.mff.cuni.cz/~courses/npfl129/2526/slides/?09
#### Reading: https://ufal.mff.cuni.cz/~courses/npfl129/2526/slides.pdf/npfl129-2526-09.pdf,PDF Slides
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl129/2526/npfl129-2526-09-czech.mp4, CS Lecture
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl129/2526/npfl129-2526-09-english.mp4, EN Lecture
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl129/2526/npfl129-2526-09-practicals-english.mp4, EN Practicals
#### Lecture assignment: decision_tree
#### Lecture assignment: random_forest
#### Lecture assignment: miniaturization
#### Questions: #lecture_9_questions

**Learning objectives.** After the lecture you should be able to

- Ensemble models with uncorrelated predictions.

- Distill ensembles into smaller models.

- Implement Decision Trees and Random Forests for classification and regression

- Explain how the splitting criterion depend on optimized loss function

- Tell how Random Forests differ from Gradient Boosted Decision Trees

**Covered topics** and where to find more:

- Model ensembling [Section 14.2 of PRML]

- Decision trees [Section 14.4 of PRML]
  - [Decision trees demo](https://mlu-explain.github.io/decision-tree/) by Jared Wilber & Lucía Santamaría

- Random forests
  - [Random forests demo](https://mlu-explain.github.io/random-forest/) by Jenny Yeon & Jared Wilber

Recording of the Czech lecture failed, please use the English recording instead. Assignments for the 9th lecture were discussed jointly with the assignments from the 8th lecture and discussed in the video from the previous practicals.
