### Lecture: 6. Representing Text (TF-IDF, Word2Vec)
#### Date: Nov 7
#### Slides: https://ufal.mff.cuni.cz/~courses/npfl129/2324/slides/?06
#### Reading: https://ufal.mff.cuni.cz/~courses/npfl129/2324/slides.pdf/npfl129-2324-06.pdf,PDF Slides
#### Lecture assignment: tf_idf
#### Lecture assignment: imdb_sentiment
#### Lecture assignment: diacritization_dictionary
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl129/2324/npfl129-2324-06-czech.mp4, CS Lecture
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl129/2324/npfl129-2324-06-english.mp4, EN Lecture
#### Questions: #lecture_6_questions

**Learning objectives.** After the lecture you shoud be able to

- Use TF-IDF for representing documents and explain its information-theoretical
  interpretation.
- Explain training of Word2Vec as a special case of logistic regression.
- Use pre-trained word embeddings for simple NLP tasks.


**Covered topics** and where to find more:

- TF-IDF
- Word2Vec ([original paper Mikolov et al., 2013](https://papers.nips.cc/paper_files/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf))

After the lecture: short and non-comprehensive [**recap quiz**](http://quest.ms.mff.cuni.cz/class-quiz/quiz/ml_intro_lect06).
