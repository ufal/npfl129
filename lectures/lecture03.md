### Lecture: 3. Peceptron, Logistic Regression
#### Date: Oct 17
#### Slides: https://ufal.mff.cuni.cz/~courses/npfl129/2324/slides/?03
#### Reading: https://ufal.mff.cuni.cz/~courses/npfl129/2324/slides.pdf/npfl129-2324-03.pdf, PDF Slides
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl129/2324/npfl129-2324-03-czech.mp4, CS Lecture
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl129/2324/npfl129-2324-03-practicals-czech.mp4, CS Practicals
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl129/2324/npfl129-2324-03-english.mp4, EN Lecture
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl129/2324/npfl129-2324-03-practicals-english.mp4, EN Practicals
#### Lecture assignment: perceptron
#### Lecture assignment: logistic_regression_sgd
#### Lecture assignment: grid_search
#### Lecture assignment: thyroid_competition
#### Questions: #lecture_3_questions

**Learning objectives.** After the lecture you shoud be able to

- Think about binary classification using **geometric intuition** and use the
  **perceptron algorithm**.
- Define the **main concepts of information theory** (entropy, cross-entropy,
  KL-divergence) and prove their basic properties.
- Derive training objectives using the **maximum likelihood principle**.
- Implement and use **logistic regression** for binary classification with SGD.

**Covered topics** and where to find more:

- Linear models for classification [Section 4.1.1 of PRML]
- Perceptron algorithm [Section 4.1.7 of PRML]
- Probability distributions [Bernoulli Section 2.1, Categorical Section 2.2, Gaussian Section 2.3 of PRML]
- Information theory [Section 1.6 of PRML]
- Maximum likelihood estimation [Section 1.2.5 of PRML]
- Logistic regression [Section 4.3.2 of PRML]
- Cross-validation [Section 1.3 of PRML]
- [Logistic regression demo](https://mlu-explain.github.io/logistic-regression) by Jared Willber

After the lecture: short and non-comprehensive [**recap quiz**](http://quest.ms.mff.cuni.cz/class-quiz/quiz/ml_intro_lect03).
